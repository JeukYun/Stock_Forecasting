{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서(tensor)\n",
    "tensor : 배열(array), 행렬(matrix)과 매우 유사한 자료구조. pyTorch에서는 텐서를 사용하여 모델의 입/출력, 모델의 매개변수들을 부호화(encode)<br>\n",
    "실제로 tensor와 NumPy의 배열(array)은 종종 동일한 메모리를 공유할 수 있어 데이터를 복사할 필요가 없음.<br>\n",
    "tensor는 또한 자동미분에 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor초기화\n",
    "- tensor의 경우 여러 방법으로 초기화 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터로부터 직접 생성\n",
    "\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Numpy 배열로부터 생성하기\n",
    "\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.6407, 0.2535],\n",
      "        [0.1566, 0.3907]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 다른 tensor로 부터 생성하기\n",
    "#    명시적으로 재정의하지 않는경우 인자로 주어진 텐서의 속성(모양,자료형)을 유지\n",
    "\n",
    "x_ones = torch.ones_like(x_data) # x_data의 속성을 유지합니다.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # x_data의 속성을 변환.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2106, 0.3181, 0.4336],\n",
      "        [0.0529, 0.3168, 0.0535]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 4. 무작위 또는 상수값 사용\n",
    "\n",
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape) # 랜덤값 \n",
    "ones_tensor = torch.ones(shape) # 1값\n",
    "zeros_tensor = torch.zeros(shape) # 0값\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor의 속성\n",
    "- tensor의 속성은 모양(shape), 자료형(datatype)및 어느 장치에 저장되는지 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3506, 0.1108, 0.8268, 0.0819],\n",
      "        [0.5886, 0.9464, 0.6833, 0.1212],\n",
      "        [0.9839, 0.9667, 0.0623, 0.6912]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(tensor)\n",
    "print(f\"Shape of tensor: {tensor.shape}\") # shape\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\") # Dtype\n",
    "print(f\"Device tensor is stored on: {tensor.device}\") # 저장위치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor 연산\n",
    "- 전치(transposing), 인덱싱(indexing), 슬라이싱(slicing) 수학계산, 선형대수, 임의샘플링 등 tensor 연산 가능\n",
    "- 기본적으로 tensor는 CPU에 생성, .to 메서드를 사용하면 GPU로 tensor를 명시적으로 이동 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not usable\n"
     ]
    }
   ],
   "source": [
    "# GPU가 존재하면 텐서를 이동.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")\n",
    "else:\n",
    "    print(\"not usable\") #GPU가 없는경우 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy식 표준 인덱싱, 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3556, 0.9199, 0.5411, 0.7954],\n",
      "        [0.2764, 0.3899, 0.1533, 0.0477],\n",
      "        [0.5737, 0.2577, 0.4229, 0.3384],\n",
      "        [0.2880, 0.2066, 0.1863, 0.3140]])\n",
      "first row : tensor([0.3556, 0.9199, 0.5411, 0.7954])\n",
      "first column : tensor([0.3556, 0.2764, 0.5737, 0.2880])\n",
      "last column : tensor([0.7954, 0.0477, 0.3384, 0.3140])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "\n",
    "print(tensor)\n",
    "print(f\"first row : {tensor[0]}\")\n",
    "print(f\"first column : {tensor[:,0]}\")\n",
    "print(f\"last column : {tensor[..., -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3556, 0.9199, 0.5411, 0.7954, 0.3556, 0.9199, 0.5411, 0.7954, 0.3556,\n",
      "         0.9199, 0.5411, 0.7954],\n",
      "        [0.2764, 0.3899, 0.1533, 0.0477, 0.2764, 0.3899, 0.1533, 0.0477, 0.2764,\n",
      "         0.3899, 0.1533, 0.0477],\n",
      "        [0.5737, 0.2577, 0.4229, 0.3384, 0.5737, 0.2577, 0.4229, 0.3384, 0.5737,\n",
      "         0.2577, 0.4229, 0.3384],\n",
      "        [0.2880, 0.2066, 0.1863, 0.3140, 0.2880, 0.2066, 0.1863, 0.3140, 0.2880,\n",
      "         0.2066, 0.1863, 0.3140]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim = 1) #dim = 1 (열방향 연결)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8980, 0.5778, 0.9390, 0.6430],\n",
      "        [0.5778, 0.2542, 0.3400, 0.2037],\n",
      "        [0.9390, 0.3400, 0.6889, 0.4035],\n",
      "        [0.6430, 0.2037, 0.4035, 0.2589]])\n",
      "tensor([[1.8980, 0.5778, 0.9390, 0.6430],\n",
      "        [0.5778, 0.2542, 0.3400, 0.2037],\n",
      "        [0.9390, 0.3400, 0.6889, 0.4035],\n",
      "        [0.6430, 0.2037, 0.4035, 0.2589]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.8980, 0.5778, 0.9390, 0.6430],\n",
       "        [0.5778, 0.2542, 0.3400, 0.2037],\n",
       "        [0.9390, 0.3400, 0.6889, 0.4035],\n",
       "        [0.6430, 0.2037, 0.4035, 0.2589]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서간의 행렬 곱 계산(y1, y2, y3는 같은값을 갖는다)\n",
    "\n",
    "y1 = tensor @ tensor.T # @ : 행렬간의 곱셈을 나타냄\n",
    "print(y1)\n",
    "\n",
    "y2 = tensor.matmul(tensor.T) # 텐서와 텐서의 전치행렬의 곱 (y1과 같음)\n",
    "print(y2)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단일요소 tensor : tensor의 모든값을 하나로 집계, item() 을 사용하여 python 숫자값으로 변환 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0668) 6.066757678985596 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "\n",
    "print(agg, agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in_place 연산 : 연산결과를 저장, _ 접미사를 갖는다. <br>\n",
    "ex) x.copy_(y) 나 x.t_()는 x를 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3556, 0.9199, 0.5411, 0.7954],\n",
      "        [0.2764, 0.3899, 0.1533, 0.0477],\n",
      "        [0.5737, 0.2577, 0.4229, 0.3384],\n",
      "        [0.2880, 0.2066, 0.1863, 0.3140]])\n",
      "\n",
      "tensor([[5.3556, 5.9199, 5.5411, 5.7954],\n",
      "        [5.2764, 5.3899, 5.1533, 5.0477],\n",
      "        [5.5737, 5.2577, 5.4229, 5.3384],\n",
      "        [5.2880, 5.2066, 5.1863, 5.3140]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor}\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy변환\n",
    "- CPU상의 tensor와 Numpy배열은 메모리 공간을 공유, 하나를 변경시 다른 하나도 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor를 Numpy배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([1., 1., 1., 1., 1.])\n",
      "n : [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t : {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n : {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# tensor 의 변경사항이 Numpy 배열에 반영\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy배열을 tensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([3., 3., 3., 3., 3.])\n",
      "n: [3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out = n) # out = n : 결과값을 n에 다시 저장\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
